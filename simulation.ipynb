{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SPM Assignment 04: Agile Software Delivery Simulation\n",
        "## Monte Carlo Simulation for Multi-Team Project Optimization\n",
        "\n",
        "**Course:** Software Project Management  \n",
        "**Assignment:** Comprehensive simulation model for optimizing Agile software delivery  \n",
        "**Date:** Fall 2025\n",
        "\n",
        "This notebook implements a complete Monte Carlo simulation for predicting project completion, analyzing risks, and optimizing resource allocation for a multi-team Agile project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "SPM Assignment 04: Agile Software Delivery Simulation\n",
        "Comprehensive Monte Carlo Simulation Script\n",
        "\n",
        "This script runs the complete simulation and generates all required outputs.\n",
        "It can be run standalone or executed cell-by-cell in a Jupyter notebook.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "from scipy import stats\n",
        "from collections import defaultdict\n",
        "import warnings\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Configure plotting\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs('output', exist_ok=True)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"SPM ASSIGNMENT 04: AGILE SOFTWARE DELIVERY SIMULATION\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\n\u2713 Libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SECTION 1: PROJECT PLANNING AND SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SECTION 1: PROJECT PLANNING AND SETUP\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Load data\n",
        "print(\"\\nLoading project data...\")\n",
        "backlog_df = pd.read_csv('data/backlog.csv')\n",
        "print(f\"  \u2713 Backlog: {len(backlog_df)} user stories\")\n",
        "\n",
        "with open('data/teams.json', 'r') as f:\n",
        "    teams_data = json.load(f)\n",
        "print(f\"  \u2713 Teams: {len(teams_data['teams'])} teams\")\n",
        "\n",
        "with open('data/risks.json', 'r') as f:\n",
        "    risks_data = json.load(f)\n",
        "print(f\"  \u2713 Risks: {len(risks_data['risks'])} risks\")\n",
        "\n",
        "# Analyze backlog\n",
        "total_story_points = backlog_df['Story Points'].sum()\n",
        "avg_tech_debt = backlog_df['Technical Debt Factor'].mean()\n",
        "\n",
        "print(f\"\\nBacklog Analysis:\")\n",
        "print(f\"  Total Story Points: {total_story_points}\")\n",
        "print(f\"  Average Technical Debt Factor: {avg_tech_debt:.2%}\")\n",
        "\n",
        "# Complexity breakdown\n",
        "complexity_breakdown = backlog_df.groupby('Complexity')['Story Points'].agg(['count', 'sum'])\n",
        "print(f\"\\nComplexity Distribution:\")\n",
        "print(complexity_breakdown)\n",
        "\n",
        "# Priority breakdown\n",
        "priority_breakdown = backlog_df.groupby('Priority')['Story Points'].sum()\n",
        "print(f\"\\nPriority Distribution:\")\n",
        "print(priority_breakdown)\n",
        "\n",
        "# Dependencies\n",
        "def parse_dependencies(dep_str):\n",
        "    if pd.isna(dep_str) or dep_str == '':\n",
        "        return []\n",
        "    return [d.strip() for d in str(dep_str).split('|')]\n",
        "\n",
        "backlog_df['Parsed_Dependencies'] = backlog_df['Dependencies'].apply(parse_dependencies)\n",
        "backlog_df['Dependency_Count'] = backlog_df['Parsed_Dependencies'].apply(len)\n",
        "\n",
        "print(f\"\\nDependency Analysis:\")\n",
        "print(f\"  Stories with dependencies: {len(backlog_df[backlog_df['Dependency_Count'] > 0])}\")\n",
        "print(f\"  Stories ready to start: {len(backlog_df[backlog_df['Dependency_Count'] == 0])}\")\n",
        "\n",
        "# Team configuration\n",
        "teams = teams_data['teams']\n",
        "total_velocity = sum(team['average_velocity'] for team in teams)\n",
        "total_cost = sum(team['cost_per_sprint'] for team in teams)\n",
        "\n",
        "print(f\"\\nTeam Configuration:\")\n",
        "for team in teams:\n",
        "    print(f\"  {team['team_name']}: {team['average_velocity']} SP/sprint, ${team['cost_per_sprint']:,}/sprint\")\n",
        "print(f\"  Combined Velocity: {total_velocity} SP/sprint\")\n",
        "print(f\"  Combined Cost: ${total_cost:,}/sprint\")\n",
        "\n",
        "# Baseline estimates\n",
        "baseline_sprints = np.ceil(total_story_points / total_velocity)\n",
        "baseline_cost = baseline_sprints * total_cost\n",
        "\n",
        "print(f\"\\nBaseline Estimates (ideal scenario):\")\n",
        "print(f\"  Estimated Sprints: {baseline_sprints:.0f}\")\n",
        "print(f\"  Estimated Cost: ${baseline_cost:,.0f}\")\n",
        "print(f\"  Estimated Duration: {baseline_sprints * 2:.0f} weeks\")\n",
        "\n",
        "# Simulation configuration\n",
        "SIMULATION_CONFIG = {\n",
        "    'num_simulations': 1000,\n",
        "    'sprint_duration_weeks': 2,\n",
        "    'min_sprints': 10,\n",
        "    'max_sprints': 50,\n",
        "    'scope_change_sprint': 5,\n",
        "    'scope_change_points': 58,\n",
        "    'technical_debt_accumulation_rate': 0.02,\n",
        "    'resource_contention_probability': 0.25,\n",
        "    'resource_contention_impact': 0.10,\n",
        "}\n",
        "\n",
        "TEAMS_CONFIG = teams\n",
        "RISKS_CONFIG = risks_data['risks']\n",
        "\n",
        "print(f\"\\n\u2713 Section 1 Complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SECTION 2: VELOCITY, RESOURCE, AND TECHNICAL DEBT MODELING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SECTION 2: VELOCITY AND TECHNICAL DEBT MODELING\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def simulate_sprint_velocity(team, sprint_num, technical_debt_factor, resource_contention=False):\n",
        "    \"\"\"Simulate team velocity for a single sprint\"\"\"\n",
        "    base_velocity = np.random.normal(team['average_velocity'], team['velocity_std'])\n",
        "    base_velocity = max(0, base_velocity)\n",
        "    effective_velocity = base_velocity * (1 - technical_debt_factor)\n",
        "    if resource_contention:\n",
        "        effective_velocity *= (1 - SIMULATION_CONFIG['resource_contention_impact'])\n",
        "    return effective_velocity\n",
        "\n",
        "def calculate_technical_debt(completed_points):\n",
        "    \"\"\"Calculate cumulative technical debt factor\"\"\"\n",
        "    avg_debt = avg_tech_debt\n",
        "    cumulative_debt = avg_debt * (1 + SIMULATION_CONFIG['technical_debt_accumulation_rate'])\n",
        "    return min(cumulative_debt, 0.30)\n",
        "\n",
        "def check_resource_contention():\n",
        "    \"\"\"Check if resource contention occurs\"\"\"\n",
        "    return np.random.random() < SIMULATION_CONFIG['resource_contention_probability']\n",
        "\n",
        "print(\"\\n\u2713 Velocity simulation functions defined\")\n",
        "\n",
        "# Test velocity simulation\n",
        "test_team = TEAMS_CONFIG[0]\n",
        "test_velocities = [simulate_sprint_velocity(test_team, 1, 0.0, False) for _ in range(100)]\n",
        "print(f\"\\nTest: {test_team['team_name']}\")\n",
        "print(f\"  Simulated mean velocity: {np.mean(test_velocities):.2f} SP\")\n",
        "print(f\"  Expected: {test_team['average_velocity']} SP\")\n",
        "\n",
        "print(f\"\\n\u2713 Section 2 Complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SECTION 3: RISK AND SCOPE MANAGEMENT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SECTION 3: RISK AND SCOPE MANAGEMENT\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def check_risk_occurrence(risk, sprint_num):\n",
        "    \"\"\"Check if a risk occurs based on probability\"\"\"\n",
        "    return np.random.random() < risk['probability']\n",
        "\n",
        "def apply_risk_impact(risk, current_velocity, current_cost, sprint_num, risk_active_sprints):\n",
        "    \"\"\"Apply risk impact based on type\"\"\"\n",
        "    risk_id = risk['risk_id']\n",
        "    impact_type = risk['impact_type']\n",
        "    impact_value = risk['impact_value']\n",
        "    \n",
        "    modified_velocity = current_velocity\n",
        "    modified_cost = current_cost\n",
        "    delay_sprints = 0\n",
        "    \n",
        "    if risk_id in risk_active_sprints and risk_active_sprints[risk_id] > 0:\n",
        "        risk_active_sprints[risk_id] -= 1\n",
        "        if impact_type == 'velocity_reduction':\n",
        "            modified_velocity = current_velocity * (1 - impact_value)\n",
        "    else:\n",
        "        if impact_type == 'velocity_reduction':\n",
        "            modified_velocity = current_velocity * (1 - impact_value)\n",
        "            duration = risk.get('duration_sprints', 1)\n",
        "            risk_active_sprints[risk_id] = duration - 1\n",
        "        elif impact_type == 'cost_increase':\n",
        "            if isinstance(impact_value, float) and impact_value < 1:\n",
        "                modified_cost = current_cost * (1 + impact_value)\n",
        "            else:\n",
        "                modified_cost = current_cost + impact_value\n",
        "        elif impact_type == 'delay':\n",
        "            delay_sprints = int(impact_value)\n",
        "    \n",
        "    return modified_velocity, modified_cost, delay_sprints, risk_active_sprints\n",
        "\n",
        "print(\"\\n\u2713 Risk simulation functions defined\")\n",
        "\n",
        "# Test risk occurrence\n",
        "print(\"\\nRisk probability test (100 sprints):\")\n",
        "for risk in RISKS_CONFIG[:3]:\n",
        "    occurrences = sum(check_risk_occurrence(risk, i) for i in range(100))\n",
        "    print(f\"  {risk['risk_name']}: {occurrences}% (expected {risk['probability']*100:.0f}%)\")\n",
        "\n",
        "print(f\"\\n\u2713 Section 3 Complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SECTION 4: MONTE CARLO SIMULATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SECTION 4: MONTE CARLO SIMULATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def run_single_simulation(sim_id, backlog_df, teams, risks, config):\n",
        "    \"\"\"Run a single simulation iteration\"\"\"\n",
        "    remaining_points = total_story_points\n",
        "    completed_points = 0\n",
        "    current_sprint = 0\n",
        "    total_cost = 0\n",
        "    technical_debt = 0\n",
        "    risk_active_sprints = {}\n",
        "    delays_accumulated = 0\n",
        "    sprint_data = []\n",
        "    risks_occurred = []\n",
        "    scope_change_applied = False\n",
        "    \n",
        "    while remaining_points > 0 and current_sprint < config['max_sprints']:\n",
        "        current_sprint += 1\n",
        "        \n",
        "        if current_sprint == config['scope_change_sprint'] and not scope_change_applied:\n",
        "            remaining_points += config['scope_change_points']\n",
        "            scope_change_applied = True\n",
        "        \n",
        "        if delays_accumulated > 0:\n",
        "            delays_accumulated -= 1\n",
        "            sprint_data.append({\n",
        "                'sprint': current_sprint, 'velocity': 0, 'completed': 0,\n",
        "                'remaining': remaining_points, 'cost': 0,\n",
        "                'technical_debt': technical_debt, 'delayed': True\n",
        "            })\n",
        "            continue\n",
        "        \n",
        "        technical_debt = calculate_technical_debt(completed_points)\n",
        "        has_contention = check_resource_contention()\n",
        "        \n",
        "        sprint_velocity_total = 0\n",
        "        sprint_cost_total = 0\n",
        "        \n",
        "        for team in teams:\n",
        "            team_velocity = simulate_sprint_velocity(team, current_sprint, technical_debt, has_contention)\n",
        "            team_cost = team['cost_per_sprint']\n",
        "            \n",
        "            for risk in risks:\n",
        "                if check_risk_occurrence(risk, current_sprint):\n",
        "                    team_velocity, team_cost, delay, risk_active_sprints = apply_risk_impact(\n",
        "                        risk, team_velocity, team_cost, current_sprint, risk_active_sprints\n",
        "                    )\n",
        "                    if delay > 0:\n",
        "                        delays_accumulated += delay\n",
        "                    risks_occurred.append({\n",
        "                        'sprint': current_sprint, 'risk': risk['risk_name'],\n",
        "                        'impact': risk['impact_description']\n",
        "                    })\n",
        "            \n",
        "            sprint_velocity_total += team_velocity\n",
        "            sprint_cost_total += team_cost\n",
        "        \n",
        "        points_completed = min(sprint_velocity_total, remaining_points)\n",
        "        remaining_points -= points_completed\n",
        "        completed_points += points_completed\n",
        "        total_cost += sprint_cost_total\n",
        "        \n",
        "        sprint_data.append({\n",
        "            'sprint': current_sprint, 'velocity': sprint_velocity_total,\n",
        "            'completed': points_completed, 'remaining': remaining_points,\n",
        "            'cost': sprint_cost_total, 'technical_debt': technical_debt,\n",
        "            'delayed': False\n",
        "        })\n",
        "    \n",
        "    return {\n",
        "        'sim_id': sim_id, 'total_sprints': current_sprint, 'total_cost': total_cost,\n",
        "        'completed_points': completed_points, 'risks_occurred': len(risks_occurred),\n",
        "        'sprint_data': sprint_data, 'risks_detail': risks_occurred,\n",
        "        'scope_change_applied': scope_change_applied\n",
        "    }\n",
        "\n",
        "# Run simulations\n",
        "print(f\"\\nRunning {SIMULATION_CONFIG['num_simulations']} Monte Carlo simulations...\")\n",
        "print(\"This will take a few minutes...\\n\")\n",
        "\n",
        "simulation_results = []\n",
        "for sim_id in range(SIMULATION_CONFIG['num_simulations']):\n",
        "    if (sim_id + 1) % 100 == 0:\n",
        "        print(f\"  Progress: {sim_id + 1}/{SIMULATION_CONFIG['num_simulations']}\")\n",
        "    result = run_single_simulation(sim_id, backlog_df, TEAMS_CONFIG, RISKS_CONFIG, SIMULATION_CONFIG)\n",
        "    simulation_results.append(result)\n",
        "\n",
        "sprints_to_completion = [r['total_sprints'] for r in simulation_results]\n",
        "total_costs = [r['total_cost'] for r in simulation_results]\n",
        "risks_occurred_counts = [r['risks_occurred'] for r in simulation_results]\n",
        "\n",
        "print(f\"\\n\u2713 All simulations completed!\")\n",
        "\n",
        "print(\"\\nResults Summary:\")\n",
        "print(f\"  Sprints - Mean: {np.mean(sprints_to_completion):.2f}, Median: {np.median(sprints_to_completion):.2f}\")\n",
        "print(f\"  Cost - Mean: ${np.mean(total_costs):,.0f}, Median: ${np.median(total_costs):,.0f}\")\n",
        "print(f\"  Risks - Mean occurrences: {np.mean(risks_occurred_counts):.2f}\")\n",
        "\n",
        "# Confidence intervals\n",
        "print(\"\\nConfidence Intervals:\")\n",
        "sprints_sorted = np.sort(sprints_to_completion)\n",
        "ci_50 = (np.percentile(sprints_sorted, 25), np.percentile(sprints_sorted, 75))\n",
        "ci_80 = (np.percentile(sprints_sorted, 10), np.percentile(sprints_sorted, 90))\n",
        "ci_95 = (np.percentile(sprints_sorted, 2.5), np.percentile(sprints_sorted, 97.5))\n",
        "\n",
        "print(f\"  50% CI: {ci_50[0]:.1f} - {ci_50[1]:.1f} sprints\")\n",
        "print(f\"  80% CI: {ci_80[0]:.1f} - {ci_80[1]:.1f} sprints\")\n",
        "print(f\"  95% CI: {ci_95[0]:.1f} - {ci_95[1]:.1f} sprints\")\n",
        "\n",
        "baseline_prob = np.sum(np.array(sprints_to_completion) <= baseline_sprints) / len(sprints_to_completion)\n",
        "print(f\"\\nProbability of baseline completion: {baseline_prob:.1%}\")\n",
        "\n",
        "print(f\"\\n\u2713 Section 4 Complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SECTION 5: SENSITIVITY ANALYSIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SECTION 5: SENSITIVITY ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nAnalyzing \u00b120% variation in key parameters...\")\n",
        "\n",
        "sensitivity_params = {\n",
        "    'team_velocity': {\n",
        "        'description': 'Team Average Velocity',\n",
        "        'base_value': np.mean([t['average_velocity'] for t in TEAMS_CONFIG]),\n",
        "    },\n",
        "    'velocity_std': {\n",
        "        'description': 'Velocity Standard Deviation',\n",
        "        'base_value': np.mean([t['velocity_std'] for t in TEAMS_CONFIG]),\n",
        "    },\n",
        "}\n",
        "\n",
        "sensitivity_results = {}\n",
        "num_sens_sims = 100\n",
        "\n",
        "for param_name, param_info in sensitivity_params.items():\n",
        "    print(f\"\\nTesting {param_info['description']}...\")\n",
        "    \n",
        "    # Low variation\n",
        "    if param_name == 'team_velocity':\n",
        "        teams_low = [dict(t, average_velocity=t['average_velocity'] * 0.8) for t in TEAMS_CONFIG]\n",
        "        teams_high = [dict(t, average_velocity=t['average_velocity'] * 1.2) for t in TEAMS_CONFIG]\n",
        "    else:\n",
        "        teams_low = [dict(t, velocity_std=t['velocity_std'] * 0.8) for t in TEAMS_CONFIG]\n",
        "        teams_high = [dict(t, velocity_std=t['velocity_std'] * 1.2) for t in TEAMS_CONFIG]\n",
        "    \n",
        "    low_results = [run_single_simulation(0, backlog_df, teams_low, RISKS_CONFIG, SIMULATION_CONFIG)['total_sprints']\n",
        "                   for _ in range(num_sens_sims)]\n",
        "    high_results = [run_single_simulation(0, backlog_df, teams_high, RISKS_CONFIG, SIMULATION_CONFIG)['total_sprints']\n",
        "                    for _ in range(num_sens_sims)]\n",
        "    \n",
        "    low_mean = np.mean(low_results)\n",
        "    high_mean = np.mean(high_results)\n",
        "    impact = abs(high_mean - low_mean)\n",
        "    \n",
        "    sensitivity_results[param_name] = {\n",
        "        'description': param_info['description'],\n",
        "        'base_value': param_info['base_value'],\n",
        "        'low_sprints': low_mean,\n",
        "        'high_sprints': high_mean,\n",
        "        'impact': impact\n",
        "    }\n",
        "    \n",
        "    print(f\"  Low (-20%): {low_mean:.2f} sprints\")\n",
        "    print(f\"  High (+20%): {high_mean:.2f} sprints\")\n",
        "    print(f\"  Impact: {impact:.2f} sprints\")\n",
        "\n",
        "print(f\"\\n\u2713 Section 5 Complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GENERATE VISUALIZATIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"GENERATING VISUALIZATIONS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 1. Backlog Analysis\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "axes[0, 0].hist(backlog_df['Story Points'], bins=7, edgecolor='black', alpha=0.7)\n",
        "axes[0, 0].set_xlabel('Story Points')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].set_title('Story Points Distribution')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "complexity_counts = backlog_df['Complexity'].value_counts()\n",
        "axes[0, 1].bar(complexity_counts.index, complexity_counts.values, edgecolor='black', alpha=0.7)\n",
        "axes[0, 1].set_title('Complexity Distribution')\n",
        "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "priority_counts = backlog_df['Priority'].value_counts()\n",
        "axes[1, 0].pie(priority_counts.values, labels=priority_counts.index, autopct='%1.1f%%')\n",
        "axes[1, 0].set_title('Priority Distribution')\n",
        "\n",
        "axes[1, 1].hist(backlog_df['Technical Debt Factor'], bins=20, edgecolor='black', alpha=0.7)\n",
        "axes[1, 1].axvline(avg_tech_debt, color='red', linestyle='--', linewidth=2, label=f'Mean: {avg_tech_debt:.2%}')\n",
        "axes[1, 1].set_xlabel('Technical Debt Factor')\n",
        "axes[1, 1].set_ylabel('Frequency')\n",
        "axes[1, 1].set_title('Technical Debt Distribution')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('output/backlog_analysis.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"  \u2713 backlog_analysis.png\")\n",
        "\n",
        "# 2. Monte Carlo Completion\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "axes[0].hist(sprints_to_completion, bins=30, edgecolor='black', alpha=0.7, color='skyblue')\n",
        "axes[0].axvline(np.mean(sprints_to_completion), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(sprints_to_completion):.1f}')\n",
        "axes[0].axvline(baseline_sprints, color='orange', linestyle='--', linewidth=2, label=f'Baseline: {baseline_sprints:.0f}')\n",
        "axes[0].set_xlabel('Sprints to Completion')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "axes[0].set_title('Project Completion Distribution')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "axes[1].hist(total_costs, bins=30, edgecolor='black', alpha=0.7, color='lightcoral')\n",
        "axes[1].axvline(np.mean(total_costs), color='red', linestyle='--', linewidth=2, label=f'Mean: ${np.mean(total_costs):,.0f}')\n",
        "axes[1].set_xlabel('Total Project Cost ($)')\n",
        "axes[1].set_ylabel('Frequency')\n",
        "axes[1].set_title('Project Cost Distribution')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('output/monte_carlo_completion.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"  \u2713 monte_carlo_completion.png\")\n",
        "\n",
        "# 3. Monte Carlo Cost\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.hist(total_costs, bins=30, edgecolor='black', alpha=0.7, color='lightcoral')\n",
        "ax.axvline(np.mean(total_costs), color='red', linestyle='--', linewidth=2, label=f'Mean: ${np.mean(total_costs):,.0f}')\n",
        "ax.set_xlabel('Total Project Cost ($)')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_title('Cost Distribution')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "plt.tight_layout()\n",
        "plt.savefig('output/monte_carlo_cost.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"  \u2713 monte_carlo_cost.png\")\n",
        "\n",
        "# 4. Burndown Chart\n",
        "median_idx = np.argsort(sprints_to_completion)[len(sprints_to_completion)//2]\n",
        "rep_sim = simulation_results[median_idx]\n",
        "\n",
        "sprint_nums = [0] + [d['sprint'] for d in rep_sim['sprint_data']]\n",
        "total_with_scope = total_story_points + SIMULATION_CONFIG['scope_change_points']\n",
        "remaining_work = [total_with_scope] + [d['remaining'] for d in rep_sim['sprint_data']]\n",
        "\n",
        "ideal_line = [total_with_scope - (total_with_scope / (len(sprint_nums)-1)) * i for i in range(len(sprint_nums))]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "ax.plot(sprint_nums, remaining_work, marker='o', linewidth=2, markersize=4, label='Actual', color='blue')\n",
        "ax.plot(sprint_nums, ideal_line, linestyle='--', linewidth=2, label='Ideal', color='green', alpha=0.7)\n",
        "ax.axvline(SIMULATION_CONFIG['scope_change_sprint'], color='red', linestyle='--', alpha=0.5, label='Scope Change')\n",
        "ax.set_xlabel('Sprint Number')\n",
        "ax.set_ylabel('Remaining Story Points')\n",
        "ax.set_title('Burndown Chart - Representative Simulation')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('output/burndown_chart.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"  \u2713 burndown_chart.png\")\n",
        "\n",
        "# 5. Velocity Trend\n",
        "velocity_per_sprint = [d['velocity'] for d in rep_sim['sprint_data']]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "ax.bar(sprint_nums[1:], velocity_per_sprint, alpha=0.6, label='Sprint Velocity', color='skyblue', edgecolor='black')\n",
        "ax.axhline(total_velocity, color='green', linestyle='--', linewidth=2, label=f'Expected: {total_velocity} SP', alpha=0.7)\n",
        "ax.set_xlabel('Sprint Number')\n",
        "ax.set_ylabel('Velocity (Story Points)')\n",
        "ax.set_title('Team Velocity Over Time')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "plt.tight_layout()\n",
        "plt.savefig('output/velocity_trend.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"  \u2713 velocity_trend.png\")\n",
        "\n",
        "# 6. Earned Value\n",
        "cumulative_completed = []\n",
        "cumulative_cost = []\n",
        "total_completed = 0\n",
        "total_spent = 0\n",
        "\n",
        "for d in rep_sim['sprint_data']:\n",
        "    total_completed += d['completed']\n",
        "    total_spent += d['cost']\n",
        "    cumulative_completed.append(total_completed)\n",
        "    cumulative_cost.append(total_spent)\n",
        "\n",
        "sprints = sprint_nums[1:]\n",
        "pv_per_sprint = total_with_scope / len(sprints)\n",
        "planned_value = [pv_per_sprint * (i + 1) for i in range(len(sprints))]\n",
        "earned_value = cumulative_completed.copy()\n",
        "\n",
        "current_ev = earned_value[-1]\n",
        "current_ac = cumulative_cost[-1]\n",
        "current_pv = planned_value[-1]\n",
        "cpi = current_ev / current_ac * (total_cost / total_with_scope)\n",
        "spi = current_ev / current_pv if current_pv > 0 else 1.0\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "ax.plot(sprints, planned_value, marker='s', linewidth=2, markersize=5, label='PV', color='blue')\n",
        "ax.plot(sprints, earned_value, marker='o', linewidth=2, markersize=5, label='EV', color='green')\n",
        "ax2 = ax.twinx()\n",
        "ax2.plot(sprints, [c/1000 for c in cumulative_cost], marker='^', linewidth=2, markersize=5, label='AC', color='red')\n",
        "ax.set_xlabel('Sprint')\n",
        "ax.set_ylabel('Story Points')\n",
        "ax2.set_ylabel('Cost ($1000s)')\n",
        "ax.set_title(f'Earned Value Management (CPI: {cpi:.2f}, SPI: {spi:.2f})')\n",
        "lines1, labels1 = ax.get_legend_handles_labels()\n",
        "lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "ax.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
        "ax.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('output/earned_value.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"  \u2713 earned_value.png\")\n",
        "\n",
        "# 7. Risk Impact\n",
        "all_risks_data = []\n",
        "for result in simulation_results:\n",
        "    all_risks_data.extend(result['risks_detail'])\n",
        "\n",
        "if all_risks_data:\n",
        "    risks_df = pd.DataFrame(all_risks_data)\n",
        "    risk_counts = risks_df['risk'].value_counts()\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "    \n",
        "    axes[0].barh(risk_counts.index, risk_counts.values, color='coral', edgecolor='black')\n",
        "    axes[0].set_xlabel('Occurrences')\n",
        "    axes[0].set_ylabel('Risk')\n",
        "    axes[0].set_title('Risk Occurrence Frequency')\n",
        "    axes[0].grid(True, alpha=0.3, axis='x')\n",
        "    \n",
        "    risk_names = [r['risk_name'] for r in RISKS_CONFIG]\n",
        "    risk_probs = [r['probability'] * 100 for r in RISKS_CONFIG]\n",
        "    \n",
        "    axes[1].bar(range(len(risk_names)), risk_probs, color='steelblue', edgecolor='black', alpha=0.7)\n",
        "    axes[1].set_xticks(range(len(risk_names)))\n",
        "    axes[1].set_xticklabels(risk_names, rotation=45, ha='right')\n",
        "    axes[1].set_ylabel('Probability (%)')\n",
        "    axes[1].set_title('Risk Probability Profile')\n",
        "    axes[1].grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('output/risk_impact.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(\"  \u2713 risk_impact.png\")\n",
        "\n",
        "# 8. Sensitivity Tornado\n",
        "sorted_params = sorted(sensitivity_results.items(), key=lambda x: x[1]['impact'], reverse=True)\n",
        "param_names = [item[1]['description'] for item in sorted_params]\n",
        "impacts_low = [baseline_sprints - item[1]['low_sprints'] for item in sorted_params]\n",
        "impacts_high = [item[1]['high_sprints'] - baseline_sprints for item in sorted_params]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "y_pos = np.arange(len(param_names))\n",
        "ax.barh(y_pos, impacts_low, align='center', color='lightcoral', edgecolor='black', label='-20%', alpha=0.8)\n",
        "ax.barh(y_pos, impacts_high, align='center', color='lightblue', edgecolor='black', label='+20%', alpha=0.8, left=0)\n",
        "ax.axvline(0, color='black', linewidth=2, linestyle='--', label='Baseline')\n",
        "ax.set_yticks(y_pos)\n",
        "ax.set_yticklabels(param_names)\n",
        "ax.set_xlabel('Impact on Duration (Sprints)')\n",
        "ax.set_title('Sensitivity Analysis - Tornado Chart')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3, axis='x')\n",
        "plt.tight_layout()\n",
        "plt.savefig('output/sensitivity_tornado.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"  \u2713 sensitivity_tornado.png\")\n",
        "\n",
        "# 9. Velocity Distributions\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "for idx, team in enumerate(TEAMS_CONFIG):\n",
        "    velocities = [simulate_sprint_velocity(team, 1, 0.0, False) for _ in range(1000)]\n",
        "    axes[idx].hist(velocities, bins=30, edgecolor='black', alpha=0.7, density=True)\n",
        "    axes[idx].axvline(team['average_velocity'], color='red', linestyle='--', linewidth=2, label=f\"Expected: {team['average_velocity']}\")\n",
        "    axes[idx].set_xlabel('Story Points')\n",
        "    axes[idx].set_ylabel('Density')\n",
        "    axes[idx].set_title(f\"{team['team_name']} Velocity\")\n",
        "    axes[idx].legend()\n",
        "    axes[idx].grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('output/velocity_distributions.png', dpi=300, bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"  \u2713 velocity_distributions.png\")\n",
        "\n",
        "print(\"\\n\u2713 All visualizations generated\")\n",
        "\n",
        "# Save simulation data\n",
        "with open('output/simulation_results.pkl', 'wb') as f:\n",
        "    pickle.dump({\n",
        "        'simulation_results': simulation_results,\n",
        "        'sensitivity_results': sensitivity_results,\n",
        "        'config': SIMULATION_CONFIG\n",
        "    }, f)\n",
        "\n",
        "summary_df = pd.DataFrame({\n",
        "    'Metric': ['Mean Sprints', 'Median Sprints', 'Mean Cost', 'Median Cost', 'Baseline Sprints', 'Baseline Cost'],\n",
        "    'Value': [np.mean(sprints_to_completion), np.median(sprints_to_completion), \n",
        "              np.mean(total_costs), np.median(total_costs), baseline_sprints, baseline_cost]\n",
        "})\n",
        "summary_df.to_csv('output/simulation_summary.csv', index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SIMULATION COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nAll outputs saved to output/ directory\")\n",
        "print(f\"  - 9 visualization files (PNG)\")\n",
        "print(f\"  - simulation_results.pkl (raw data)\")\n",
        "print(f\"  - simulation_summary.csv (statistics)\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}